{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0dd452",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [download/read csv file](#sec1)\n",
    "2. [Convert the labeled data set tags into the new individual tag columns](#sec2)\n",
    "3. [NLTK](#sec3)\n",
    "4. [Classifier Building](#sec4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "943f9c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "#%pip install numpy\n",
    "#%pip install pandas\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c307b7",
   "metadata": {},
   "source": [
    "<a id = \"sec1\"></a>\n",
    "## **Download/Read CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3aba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  END_TIME  \\\n",
      "0           199601         19        1100         199601       19      1300   \n",
      "1           199606         18          30         199606       18       200   \n",
      "2           199606         20        2200         199606       20      2300   \n",
      "3           199609          6        1200         199609        6      1800   \n",
      "4           199611          8        1600         199611        8      1715   \n",
      "\n",
      "   EPISODE_ID  EVENT_ID                 STATE  STATE_FIPS  ...  END_LOCATION  \\\n",
      "0     2403644   5541358  DISTRICT OF COLUMBIA          11  ...           ALL   \n",
      "1     1014286   5561204  DISTRICT OF COLUMBIA          11  ...     N PORTION   \n",
      "2     2040906   5561207  DISTRICT OF COLUMBIA          11  ...     NORTHWEST   \n",
      "3     2049837   5572405  DISTRICT OF COLUMBIA          11  ...      DOWNTOWN   \n",
      "4     2049872   5572790  DISTRICT OF COLUMBIA          11  ...      CITYWIDE   \n",
      "\n",
      "  BEGIN_LAT BEGIN_LON END_LAT  END_LON  \\\n",
      "0       NaN       NaN     NaN      NaN   \n",
      "1       NaN       NaN     NaN      NaN   \n",
      "2       NaN       NaN     NaN      NaN   \n",
      "3       NaN       NaN     NaN      NaN   \n",
      "4       NaN       NaN     NaN      NaN   \n",
      "\n",
      "                                   EPISODE_NARRATIVE EVENT_NARRATIVE  \\\n",
      "0  An unusually intense squall line, feeding on a...             NaN   \n",
      "1  Intense thunderstorms moved through the northe...             NaN   \n",
      "2  A rapidly developing thunderstorm knocked down...             NaN   \n",
      "3  Feeder bands of torrential tropical rains asso...             NaN   \n",
      "4  Several roads were briefly closed after torren...             NaN   \n",
      "\n",
      "                                   IMPACT_PREDICTORS weather_events  \\\n",
      "0   road_closure, home_damage, infrastructure_damage            NaN   \n",
      "1                                       road_closure   thunderstorm   \n",
      "2  road_closure, power_outage, tree_damage, vehic...   thunderstorm   \n",
      "3                         power_outage, road_closure      hurricane   \n",
      "4                road_closure, infrastructure_damage            NaN   \n",
      "\n",
      "  DATA_SOURCE  \n",
      "0         PDC  \n",
      "1         PDC  \n",
      "2         PDC  \n",
      "3         PDC  \n",
      "4         PDC  \n",
      "\n",
      "[5 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "# read csv\n",
    "github_csv_url = \"https://raw.githubusercontent.com/JL72005/PIT-UN-Project4/refs/heads/main/NEW_TAGS_dc_md_va_flash_floods_1996_present.xlsx%20-%20dc_md_va_flash_floods_1996_pres.csv?token=GHSAT0AAAAAADCLZGCQTGZ6S7D4POOSP64O2CBUHIA\"\n",
    "df = pd.read_csv(github_csv_url)\n",
    "# print first 5 rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6074c5",
   "metadata": {},
   "source": [
    "<a id = \"sec2\"></a>\n",
    "## **Convert the labeled data set tags into the new individual tag columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca1bb33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of tags\n",
    "tag_names = ['death','injury','evacuation','rescue','car_crash','home_damage','infrastructure_damage','soft_infrastructure_damage','road_closure','power_outage','tree_damage','vehicle_loss','agricultural_damage','campground_damage']\n",
    "#list of weather events\n",
    "weather_names = ['nor_easter','thunderstorm','hurricane','tornado','lightning','mudslide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66ba49eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate columns for OG tags\n",
    "for tag in tag_names:\n",
    "    df[tag] = 0  # Initialize column as int\n",
    "    df.loc[0:906, tag] = df.loc[0:906, 'IMPACT_PREDICTORS'].apply(str).apply(lambda x: 1 if tag in x else 0)\n",
    "\n",
    "# Populate columns for weather-related tags\n",
    "for tag in weather_names:\n",
    "    df[tag] = df['weather_events'].apply(str).apply(lambda x: 1 if tag in x else 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4407a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>death</th>\n",
       "      <th>injury</th>\n",
       "      <th>evacuation</th>\n",
       "      <th>rescue</th>\n",
       "      <th>car_crash</th>\n",
       "      <th>home_damage</th>\n",
       "      <th>infrastructure_damage</th>\n",
       "      <th>soft_infrastructure_damage</th>\n",
       "      <th>road_closure</th>\n",
       "      <th>power_outage</th>\n",
       "      <th>tree_damage</th>\n",
       "      <th>vehicle_loss</th>\n",
       "      <th>agricultural_damage</th>\n",
       "      <th>campground_damage</th>\n",
       "      <th>nor_easter</th>\n",
       "      <th>thunderstorm</th>\n",
       "      <th>hurricane</th>\n",
       "      <th>tornado</th>\n",
       "      <th>lightning</th>\n",
       "      <th>mudslide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    death  injury  evacuation  rescue  car_crash  home_damage  \\\n",
       "0       0       0           0       0          0            0   \n",
       "1       0       0           0       0          0            0   \n",
       "2       0       0           0       0          0            0   \n",
       "3       0       0           0       0          0            0   \n",
       "4       0       0           0       0          0            0   \n",
       "5       0       0           0       0          0            0   \n",
       "6       0       0           0       0          0            0   \n",
       "7       0       0           0       0          0            0   \n",
       "8       0       0           0       0          0            0   \n",
       "9       0       0           0       0          0            0   \n",
       "10      0       0           0       0          0            1   \n",
       "11      0       0           0       0          0            0   \n",
       "12      0       0           1       0          0            1   \n",
       "13      0       0           0       0          0            0   \n",
       "14      0       0           0       0          0            0   \n",
       "\n",
       "    infrastructure_damage  soft_infrastructure_damage  road_closure  \\\n",
       "0                       0                           0             0   \n",
       "1                       0                           0             0   \n",
       "2                       0                           0             1   \n",
       "3                       0                           0             1   \n",
       "4                       0                           0             1   \n",
       "5                       0                           0             1   \n",
       "6                       0                           0             0   \n",
       "7                       1                           0             1   \n",
       "8                       0                           0             1   \n",
       "9                       0                           0             1   \n",
       "10                      0                           1             1   \n",
       "11                      0                           0             0   \n",
       "12                      1                           1             1   \n",
       "13                      0                           0             0   \n",
       "14                      0                           0             1   \n",
       "\n",
       "    power_outage  tree_damage  vehicle_loss  agricultural_damage  \\\n",
       "0              1            0             1                    0   \n",
       "1              0            1             0                    0   \n",
       "2              0            1             0                    0   \n",
       "3              0            0             0                    0   \n",
       "4              0            1             0                    0   \n",
       "5              0            0             0                    0   \n",
       "6              1            0             0                    0   \n",
       "7              0            1             0                    0   \n",
       "8              0            1             1                    0   \n",
       "9              1            1             0                    0   \n",
       "10             1            1             1                    0   \n",
       "11             0            0             0                    0   \n",
       "12             1            1             1                    0   \n",
       "13             0            0             0                    0   \n",
       "14             1            1             0                    0   \n",
       "\n",
       "    campground_damage  nor_easter  thunderstorm  hurricane  tornado  \\\n",
       "0                   0           0             0          0        0   \n",
       "1                   0           0             1          0        0   \n",
       "2                   0           0             1          0        0   \n",
       "3                   0           0             0          0        0   \n",
       "4                   0           0             0          0        0   \n",
       "5                   0           0             1          0        0   \n",
       "6                   0           0             1          0        0   \n",
       "7                   0           0             1          0        0   \n",
       "8                   0           0             0          0        0   \n",
       "9                   0           0             1          0        0   \n",
       "10                  0           0             0          0        0   \n",
       "11                  0           0             1          0        0   \n",
       "12                  0           0             1          0        0   \n",
       "13                  0           0             1          0        0   \n",
       "14                  0           0             1          0        0   \n",
       "\n",
       "    lightning  mudslide  \n",
       "0           0         0  \n",
       "1           0         0  \n",
       "2           0         0  \n",
       "3           0         0  \n",
       "4           0         0  \n",
       "5           0         0  \n",
       "6           0         0  \n",
       "7           0         0  \n",
       "8           0         0  \n",
       "9           0         0  \n",
       "10          0         0  \n",
       "11          0         0  \n",
       "12          0         0  \n",
       "13          0         0  \n",
       "14          0         0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check columns\n",
    "df[tag_names+weather_names].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e43395f",
   "metadata": {},
   "source": [
    "<a id=\"sec3\"></a>\n",
    "## **NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2308888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "#%pip install nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52750cee",
   "metadata": {},
   "source": [
    "### Tokenization and Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce6d945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\jessi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jessi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOKEN_EPISODE_NARRATIVE</th>\n",
       "      <th>TOKEN_EVENT_NARRATIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unusually intense squall line feeding unseason...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intense thunderstorms moved northeast half Was...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rapidly developing thunderstorm knocked numero...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feeder bands torrential tropical rains associa...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Several roads briefly closed torrential rains ...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             TOKEN_EPISODE_NARRATIVE TOKEN_EVENT_NARRATIVE\n",
       "0  unusually intense squall line feeding unseason...                   nan\n",
       "1  Intense thunderstorms moved northeast half Was...                   nan\n",
       "2  rapidly developing thunderstorm knocked numero...                   nan\n",
       "3  Feeder bands torrential tropical rains associa...                   nan\n",
       "4  Several roads briefly closed torrential rains ...                   nan"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TOKENIZATION & REMOVING STOP WRODS\n",
    "\n",
    "#download necessary NLTK data\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "#download stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopword(text):\n",
    "  tk = RegexpTokenizer(r'\\w+')\n",
    "  word_tokens = tk.tokenize(text)\n",
    "  filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "  filtered_text = \" \".join(filtered_sentence)\n",
    "  return filtered_text\n",
    "\n",
    "df['TOKEN_EPISODE_NARRATIVE'] = df['EPISODE_NARRATIVE'].apply(str).apply(remove_stopword)\n",
    "df['TOKEN_EVENT_NARRATIVE'] = df['EVENT_NARRATIVE'].apply(str).apply(remove_stopword)\n",
    "df[['TOKEN_EPISODE_NARRATIVE', 'TOKEN_EVENT_NARRATIVE']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51226630",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e359c410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    unusu intens squall line feed unseason warm mo...\n",
       "1    intens thunderstorm move northeast half washin...\n",
       "2    rapidli develop thunderstorm knock numer tree ...\n",
       "3    feeder band torrenti tropic rain associ remnan...\n",
       "4    sever road briefli close torrenti rain associ ...\n",
       "Name: STEM_EPISODE_NARRATIVE, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEMMING\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_narrative(text):\n",
    "    token_list = text.split(\" \")\n",
    "    stemmed_list = []\n",
    "    for word in token_list:\n",
    "        stemmed_list.append(stemmer.stem(word))\n",
    "    return stemmed_list\n",
    "\n",
    "df['STEM_EPISODE_NARRATIVE'] = df['TOKEN_EPISODE_NARRATIVE'].apply(str).apply(stem_narrative).apply(lambda x: \" \".join(x)) #where x is the list of stemmed words\n",
    "df['STEM_EVENT_NARRATIVE'] = df['TOKEN_EVENT_NARRATIVE'].apply(str).apply(stem_narrative).apply(lambda x: \" \".join(x)) #where x is the list of stemmed words\n",
    "df['STEM_EPISODE_NARRATIVE'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4181959",
   "metadata": {},
   "source": [
    "### Lemmatization: Reducing word to base form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa12da80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jessi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jessi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\jessi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LEM_EPISODE_NARRATIVE</th>\n",
       "      <th>LEM_EVENT_NARRATIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unusually intense squall line feed unseasonabl...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intense thunderstorm move northeast half Washi...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rapidly develop thunderstorm knock numerous tr...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feeder band torrential tropical rain associate...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Several road briefly close torrential rain ass...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               LEM_EPISODE_NARRATIVE LEM_EVENT_NARRATIVE\n",
       "0  unusually intense squall line feed unseasonabl...                 nan\n",
       "1  Intense thunderstorm move northeast half Washi...                 nan\n",
       "2  rapidly develop thunderstorm knock numerous tr...                 nan\n",
       "3  Feeder band torrential tropical rain associate...                 nan\n",
       "4  Several road briefly close torrential rain ass...                 nan"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "\n",
    "# Helper: Convert NLTK POS tag to WordNet POS\n",
    "def get_wordnet_pos(word):\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "    return tag_dict.get(tag, wordnet.NOUN) \n",
    "\n",
    "def lemmatize_narrative(text):\n",
    "    token_list = text.split(\" \")\n",
    "    lemmatized_list = []\n",
    "    for word in token_list:\n",
    "        pos = get_wordnet_pos(word)\n",
    "        lemmatized_list.append(lemmatizer.lemmatize(word,pos))\n",
    "    lemmatized_sentence = \" \".join(lemmatized_list)\n",
    "    return lemmatized_sentence\n",
    "df['LEM_EPISODE_NARRATIVE'] = df['TOKEN_EPISODE_NARRATIVE'].apply(str).apply(lemmatize_narrative)\n",
    "df['LEM_EVENT_NARRATIVE'] = df['TOKEN_EVENT_NARRATIVE'].apply(str).apply(lemmatize_narrative)\n",
    "df[['LEM_EPISODE_NARRATIVE', 'LEM_EVENT_NARRATIVE']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac3c848",
   "metadata": {},
   "source": [
    "<a id =\"sec4\"></a>\n",
    "## **Classifier Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b452a126",
   "metadata": {},
   "source": [
    "### Corpus Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377e132d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jessi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\jessi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dead', 'casualty', 'die', 'drowns', 'swept away', 'fatal', 'perish', 'casualities', 'death', 'fatality', 'drown', 'lifeless']\n",
      "['injured', 'treated and released from Army community hospital', 'wound', 'injury', 'hurt', 'harm']\n",
      "['relocate', 'evacuate', 'strand', 'evacuation', 'climbed to safety', 'forced out', 'isolated', 'moved out', 'displace']\n",
      "['save', 'rescue', 'retrieve', 'retrieval']\n",
      "['accident', 'crashed', 'collision', 'crash', 'vehicle accident', 'car crash', 'wreck']\n",
      "['shingle', 'residence', 'residence damage', 'mobile homes', 'fence', 'porch', 'mailbox', 'house', 'shed', 'mobile home parks', 'side', 'roof collapse', 'apartment buildings', 'home', 'roof', 'house damage', 'property damage', 'flooded house', 'dwelling', 'home damage', 'residential gardens', 'gutter', 'home destroyed', 'windows,chimneys', 'basement flooded', 'garage', 'flooded home']\n",
      "['metro subway system', 'mezzanine and platform levels', 'station', 'pumping stations', 'infrastructure', 'escalator']\n",
      "['Fire Station 2', 'police station', 'restaurant', 'firehouse', 'school buses', 'business', 'school', 'church', 'greenhouse', 'stores in a shopping center', 'service station (doors)', 'school districts']\n",
      "['road closure', 'close', 'impassable', 'block']\n",
      "['blackout', 'line', 'outage', 'lost power', 'power lines', 'personal electronics equipment failures', 'loss of power', 'knocked out power', 'fallen wires', 'utility outage', 'electricity loss', 'transformer', 'power outage', 'lose power']\n",
      "['fallen trees', 'maple tree', 'downed trees', 'tree', 'limb', 'oak tree']\n",
      "['sport utility vehicle', 'van', 'car', 'train derailment', 'vehicle', 'truck', 'automobile']\n",
      "['roof off of a barn', 'agricultural/crop losses', 'farm storage building', 'barn']\n",
      "['livestock', 'dead animals', 'animal', 'dead pets', 'pet', 'cow', 'turkey', 'drowned pets', 'drowned animals', 'dog']\n",
      "['campground', 'campground erosion', 'erosion', 'trail', 'trail erosion', 'camp']\n",
      "[\"nor'easter\"]\n",
      "['thunderstorm']\n",
      "['hurricane']\n",
      "['tornado']\n",
      "['lightning', 'fire']\n",
      "['mudslide', 'landslide']\n"
     ]
    }
   ],
   "source": [
    "#take spreadsheet of tags and their key words and generate a list/corpus for every tag\n",
    "import csv\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "\n",
    "# Helper: Convert NLTK POS tag to WordNet POS\n",
    "def get_wordnet_pos(word):\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,\n",
    "        'N': wordnet.NOUN,\n",
    "        'V': wordnet.VERB,\n",
    "        'R': wordnet.ADV\n",
    "    }\n",
    "    return tag_dict.get(tag, wordnet.NOUN)  # default to noun\n",
    "\n",
    "lemmatizer2 = WordNetLemmatizer()\n",
    "with open('tag_corpus.csv','r') as inputFile:\n",
    "    data = csv.DictReader(inputFile)\n",
    "    tag_corpus = {row['Tag']: row['Similar Words'].split(', ') for row in data}\n",
    "    for tag in tag_corpus:\n",
    "        for i in range(len(tag_corpus[tag])):\n",
    "            word = tag_corpus[tag][i].strip()\n",
    "            pos = get_wordnet_pos(word)\n",
    "            tag_corpus[tag][i] = lemmatizer.lemmatize(word, pos)\n",
    "            #print(tag_corpus[tag][i])\n",
    "        tag_corpus[tag] = list(set(tag_corpus[tag])) #removes duplicates\n",
    "        print(tag_corpus[tag])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c97e7a",
   "metadata": {},
   "source": [
    "### Create Function that adds these tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b6f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_tag(text, tag): \n",
    "    for syns in tag_corpus[tag]: #the list in the tag \n",
    "        if syns in text: #if the text is in the list\n",
    "            return int(1)\n",
    "    return int(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f9f5c",
   "metadata": {},
   "source": [
    "### Apply The Function to our sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa826cdd",
   "metadata": {},
   "source": [
    "#### Real Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2460b4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>STEM_EPISODE_NARRATIVE</th>\n",
       "      <th>death</th>\n",
       "      <th>injury</th>\n",
       "      <th>evacuation</th>\n",
       "      <th>rescue</th>\n",
       "      <th>infrastructure_damage</th>\n",
       "      <th>road_closure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An unusually intense squall line, feeding on a...</td>\n",
       "      <td>unusu intens squall line feed unseason warm mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intense thunderstorms moved through the northe...</td>\n",
       "      <td>intens thunderstorm move northeast half washin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A rapidly developing thunderstorm knocked down...</td>\n",
       "      <td>rapidli develop thunderstorm knock numer tree ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feeder bands of torrential tropical rains asso...</td>\n",
       "      <td>feeder band torrenti tropic rain associ remnan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Several roads were briefly closed after torren...</td>\n",
       "      <td>sever road briefli close torrenti rain associ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tropical moisture, feeding along a south movin...</td>\n",
       "      <td>tropic moistur feed along south move cold fron...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A slow-moving line of thunderstorms dumped bet...</td>\n",
       "      <td>slow move line thunderstorm dump 2 4 3 inch ra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A thunderstorm, dumping rainfall of 3/4 to 1 i...</td>\n",
       "      <td>thunderstorm dump rainfal 3 4 1 inch citi shor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A powerful nor'easter, laden with abundant tro...</td>\n",
       "      <td>power easter laden abund tropic moistur gulf m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A line of thunderstorms produced very heavy ra...</td>\n",
       "      <td>line thunderstorm produc heavi rain move acros...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hurricane Floyd made landfall just east of Cap...</td>\n",
       "      <td>hurrican floyd made landfal east cape fear nor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>An area of showers and thunderstorms with very...</td>\n",
       "      <td>area shower thunderstorm heavi downpour move a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Showers and thunderstorms with very heavy down...</td>\n",
       "      <td>shower thunderstorm heavi downpour form distri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A thunderstorm with very heavy rainfall moved ...</td>\n",
       "      <td>thunderstorm heavi rainfal move district 3 5 p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    EPISODE_NARRATIVE  \\\n",
       "0   An unusually intense squall line, feeding on a...   \n",
       "1   Intense thunderstorms moved through the northe...   \n",
       "2   A rapidly developing thunderstorm knocked down...   \n",
       "3   Feeder bands of torrential tropical rains asso...   \n",
       "4   Several roads were briefly closed after torren...   \n",
       "5   Tropical moisture, feeding along a south movin...   \n",
       "6   A slow-moving line of thunderstorms dumped bet...   \n",
       "7   A thunderstorm, dumping rainfall of 3/4 to 1 i...   \n",
       "8   A powerful nor'easter, laden with abundant tro...   \n",
       "9   A line of thunderstorms produced very heavy ra...   \n",
       "10  Hurricane Floyd made landfall just east of Cap...   \n",
       "11  An area of showers and thunderstorms with very...   \n",
       "12  Showers and thunderstorms with very heavy down...   \n",
       "13  A thunderstorm with very heavy rainfall moved ...   \n",
       "\n",
       "                               STEM_EPISODE_NARRATIVE  death  injury  \\\n",
       "0   unusu intens squall line feed unseason warm mo...      0       0   \n",
       "1   intens thunderstorm move northeast half washin...      0       0   \n",
       "2   rapidli develop thunderstorm knock numer tree ...      0       0   \n",
       "3   feeder band torrenti tropic rain associ remnan...      0       0   \n",
       "4   sever road briefli close torrenti rain associ ...      0       0   \n",
       "5   tropic moistur feed along south move cold fron...      0       0   \n",
       "6   slow move line thunderstorm dump 2 4 3 inch ra...      0       0   \n",
       "7   thunderstorm dump rainfal 3 4 1 inch citi shor...      0       0   \n",
       "8   power easter laden abund tropic moistur gulf m...      0       0   \n",
       "9   line thunderstorm produc heavi rain move acros...      0       0   \n",
       "10  hurrican floyd made landfal east cape fear nor...      0       0   \n",
       "11  area shower thunderstorm heavi downpour move a...      0       0   \n",
       "12  shower thunderstorm heavi downpour form distri...      0       0   \n",
       "13  thunderstorm heavi rainfal move district 3 5 p...      0       0   \n",
       "\n",
       "    evacuation  rescue  infrastructure_damage  road_closure  \n",
       "0            0       0                      0             0  \n",
       "1            0       0                      0             0  \n",
       "2            0       0                      0             1  \n",
       "3            0       0                      0             1  \n",
       "4            0       0                      0             1  \n",
       "5            0       0                      0             1  \n",
       "6            0       0                      0             0  \n",
       "7            0       0                      1             1  \n",
       "8            0       0                      0             1  \n",
       "9            0       0                      0             1  \n",
       "10           0       0                      0             1  \n",
       "11           0       0                      0             0  \n",
       "12           1       0                      1             1  \n",
       "13           0       0                      0             0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the label_tag function to each row in the dataframe for each tag\n",
    "df2 = df.copy()  # Create a copy of the original dataframe to avoid modifying it directly\n",
    "for tag in tag_corpus:\n",
    "    df2.loc[0:908, tag] = df2.loc[0:908, \"STEM_EPISODE_NARRATIVE\"].apply(lambda text: label_tag(text, tag)).astype(int)\n",
    "    #print(f\"finished labeling tag: {tag}\")\n",
    "\n",
    "# check the first 15 rows of the dataframe for selected columns\n",
    "df2[['EPISODE_NARRATIVE', 'STEM_EPISODE_NARRATIVE', 'death', 'injury', 'evacuation', 'rescue', 'infrastructure_damage', 'road_closure']].head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee2b0d2",
   "metadata": {},
   "source": [
    "#### Compute the accuracy - Jessica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6541a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the accuracy \n",
    "#compare the original dataframe with the new dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3674d72",
   "metadata": {},
   "source": [
    "### visualize the impacts -Jessica and Emma \n",
    "heatmap, frequency/barchart, co-occurence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef336dd",
   "metadata": {},
   "source": [
    "### create FIS score - Danielle "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
